{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e4ec957-6d1b-41cf-ab9d-3ae248600a6f",
   "metadata": {},
   "source": [
    "# 1. Préambule\n",
    "\n",
    "## 1.1 Problématique\n",
    "\n",
    "La très jeune start-up de l'AgriTech, nommée \"**Fruits**!\", cherche à proposer des solutions innovantes pour la récolte des fruits.\n",
    "La volonté de l’entreprise est de préserver la biodiversité des fruits en permettant des traitements spécifiques pour chaque espèce de fruits en développant des robots cueilleurs intelligents.\n",
    "La start-up souhaite dans un premier temps se faire connaître en mettant à disposition du grand public une application mobile qui permettrait aux utilisateurs de prendre en photo un fruit et d'obtenir des informations sur ce fruit.\n",
    "Pour la start-up, cette application permettrait de sensibiliser le grand public à la biodiversité des fruits et de mettre en place une première version du moteur de classification des images de fruits.\n",
    "De plus, le développement de l’application mobile permettra de construire une première version de l'architecture **Big Data** nécessaire.\n",
    "\n",
    "## 1.2 Objectifs dans ce projet\n",
    "\n",
    "1. Développer une première chaîne de traitement des données qui comprendra le **preprocessing** et une étape de **réduction de dimension**.\n",
    "2. Tenir compte du fait que <u>le volume de données va augmenter très rapidement</u> après la livraison de ce projet, ce qui implique de:\n",
    " - Déployer le traitement des données dans un environnement **Big Data**\n",
    " - Développer les scripts en **pyspark** pour effectuer du **calcul distribué**\n",
    "\n",
    "## 1.3 Déroulement des étapes du projet\n",
    "\n",
    "Le projet va être réalisé en 2 temps, dans deux environnements différents. Nous allons dans un premier temps développer et exécuter notre code en local, en travaillant sur un nombre limité d'images à traiter.\n",
    "Une fois les choix techniques validés, nous déploierons notre solution dans un environnement Big Data en mode distribué.\n",
    "\n",
    "<u>Pour cette raison, ce projet sera divisé en 3 parties<u>:\n",
    "- Liste des choix techniques généraux retenus\n",
    "- Déploiement de la solution en local\n",
    "- Déploiement de la solution dans le cloud\n",
    "\n",
    "# 2. Choix techniques généraux retenus\n",
    "\n",
    "## 2.1 Calcul distribué\n",
    "\n",
    "L’énoncé du projet nous impose de développer des scripts en **pyspark** afin de prendre en compte l’augmentation très rapide du volume de donné après la livraison du projet.\n",
    "\n",
    "Lorsque l’on parle de traitement de bases de données sur python, on pense immédiatement à la librairie pandas. Cependant, lorsqu’on a affaire à des bases de données trop massives, les calculs deviennent trop lents. Heureusement, il existe une autre librairie python, assez proche de pandas, qui permet de traiter des très grandes quantités de données : PySpark. Apache Spark est un framework open-source développé par l’AMPLab de UC Berkeley permettant de traiter des bases de données massives en utilisant le calcul distribué, technique qui consiste à exploiter plusieurs unités de calcul réparties en clusters au profit d’un seul projet afin de diviser le temps d’exécution d’une requête. Spark a été développé en Scala et est au meilleur de ses capacités dans son langage natif. Cependant, la librairie PySpark propose de l’utiliser avec le langage Python, en gardant des performances similaires à des implémentations en Scala. Pyspark est donc une bonne alternative à la librairie pandas lorsqu’on cherche à traiter des jeux de données trop volumineux qui entraînent des calculs trop chronophages.\n",
    "\n",
    "Comme nous le constatons, **pySpark** est un moyen de communiquer avec **Spark** via le langage **Python**. **Spark**, quant à lui, est un outil qui permet de gérer et de coordonner l'exécution de tâches sur des données à travers un groupe d'ordinateurs. <u>Spark (ou Apache Spark) est un framework open source de calcul distribué in-memory pour le traitement et l'analyse de données massives<u>.\n",
    "\n",
    "Les applications Spark se composent d’un pilote (« driver process ») et de plusieurs exécuteurs (« executor processes »). Il peut être configuré pour être lui-même l’exécuteur (local mode) ou en utiliser autant que nécessaire pour traiter l’application, Spark prenant en charge la mise à l’échelle automatique par une configuration d’un nombre minimum et maximum d’exécuteurs.\n",
    "\n",
    "Le driver (parfois appelé « Spark Session ») distribue et planifie les tâches entre les différents exécuteurs qui les exécutent et permettent un traitement réparti. Il est le responsable de l’exécution du code sur les différentes machines.\n",
    "Chaque exécuteur est un processus Java Virtual Machine (JVM) distinct dont il est possible de configurer le nombre de CPU et la quantité de mémoire qui lui est alloué. Une seule tâche peut traiter un fractionnement de données à la fois.\n",
    "Nous utiliserons donc **Spark** et nous l’exploiterons à travers des scripts python grâce à **PySpark**, et nous **réaliserons les opérations sur un cluster de machine**.\n",
    "\n",
    "## 2.2 Transfert Learning\n",
    "\n",
    "L'énoncé du projet nous demande également de réaliser une première chaîne de traitement des données qui comprendra le preprocessing et une étape de réduction de dimension.\n",
    "Il est également précisé qu'il n'est pas nécessaire d'entraîner un modèle pour le moment.\n",
    "Nous décidons de partir sur une solution de **transfert learning**.\n",
    "Simplement, le **transfert learning** consiste à utiliser la connaissance déjà acquise par un modèle entraîné (ici **MobileNetV2**) pour l'adapter à notre problématique.\n",
    "Nous allons fournir au modèle nos images, et nous allons </u>récupérer l'avant dernière couche</u> du modèle. En effet la dernière couche de modèle est une couche softmax qui permet la classification des images ce que nous ne souhaitons pas dans ce projet.\n",
    "L'avant dernière couche correspond à un **vecteur réduit** de dimension (1,1,1280).\n",
    "Cela permettra de réaliser une première version du moteur pour la classification des images des fruits.\n",
    "**MobileNetV2** a été retenu pour sa </u>rapidité d'exécution</u>, particulièrement adaptée pour le traitement d'un gros volume de données ainsi que la </u>faible dimensionnalité du vecteur de caractéristique en sortie</u> (1,1,1280)\n",
    "\n",
    "# 3. Execution sur un cluster EMR  \n",
    "\n",
    "<u>Avant de commencer</u>, il faut s'assurer d'utiliser le **kernel pyspark**.\n",
    "En utilisant ce kernel, une session spark est créé à l'exécution de la première cellule**.\n",
    "\n",
    "## 3.1 Démarrage de la session Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f0fbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>application_1720979201060_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-21-88.eu-west-1.compute.internal:20888/proxy/application_1720979201060_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-21-146.eu-west-1.compute.internal:8042/node/containerlogs/container_1720979201060_0002_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# L'exécution de cette cellule démarre l'application Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aba202f",
   "metadata": {},
   "source": [
    "<u>Affichage des informations sur la session en cours et liens vers Spark UI</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb788991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'driverMemory': '1000M', 'executorCores': 2, 'proxyUser': 'jovyan', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>application_1720979201060_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-21-88.eu-west-1.compute.internal:20888/proxy/application_1720979201060_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-21-146.eu-west-1.compute.internal:8042/node/containerlogs/container_1720979201060_0002_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ac9832",
   "metadata": {},
   "source": [
    "## 3.2 Installation des packages\n",
    "\n",
    "Les packages nécessaires ont été installé via l'étape de **bootstrap** à l'instanciation du serveur.\n",
    "\n",
    "## 3.3 Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa11c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83663cbd",
   "metadata": {},
   "source": [
    "## 3.4 Définition des PATH pour charger les images et enregistrer les résultats\n",
    "\n",
    "Nous accédons directement à nos **données sur S3** comme si elles étaient **stockées localement**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46be859d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH:        s3://projet9-oba-data\n",
      "PATH_Data:   s3://projet9-oba-data/Test\n",
      "PATH_Result: s3://projet9-oba-data/Results"
     ]
    }
   ],
   "source": [
    "PATH = 's3://alex-martineau-p9-data'\n",
    "PATH_Data = PATH+'/Test'\n",
    "PATH_Result = PATH+'/Results'\n",
    "print('PATH:        '+\\\n",
    "      PATH+'\\nPATH_Data:   '+\\\n",
    "      PATH_Data+'\\nPATH_Result: '+PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf883c20",
   "metadata": {},
   "source": [
    "## 3.5 Traitement des données\n",
    "\n",
    "<u>Dans la suite de notre flux de travail, nous allons successivement</u> :\n",
    "1. Préparer nos données\n",
    "    1. Importer les images dans un dataframe **pandas UDF**\n",
    "    2. Associer aux images leur **label**\n",
    "    3. Préprocesser en **redimensionnant nos images pour qu'elles soient compatibles avec notre modèle**\n",
    "2. Préparer notre modèle\n",
    "    1. Importer le modèle **MobileNetV2**\n",
    "    2. Créer un **nouveau modèle** dépourvu de la dernière couche de MobileNetV2\n",
    "3. Définir le processus de chargement des images et l'application de leur featurisation à travers l'utilisation de pandas UDF\n",
    "3. Exécuter les actions d'extraction de features\n",
    "4. Enregistrer le résultat de nos actions\n",
    "5. Tester le bon fonctionnement en chargeant les données enregistrées\n",
    "\n",
    "### a) Chargement des données\n",
    "\n",
    "Les images sont chargées au format binaire, ce qui offre, plus de souplesse dans la façon de prétraiter les images.\n",
    "Avant de charger les images, nous spécifions que nous voulons charger uniquement les fichiers dont l'extension est **jpg**.\n",
    "Nous indiquons également de charger tous les objets possibles contenus dans les sous-dossiers du dossier communiqué.\n",
    "\n",
    "<u>Affichage des 5 premières images contenant</u> :\n",
    " - le path de l'image\n",
    " - la date et heure de sa dernière modification\n",
    " - sa longueur\n",
    " - son contenu encodé en valeur hexadécimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e4b319a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = spark.read.format(\"binaryFile\").option(\"pathGlobFilter\", \"*.jpg\").option(\"recursiveFileLookup\", \"true\").load(PATH_Data)\n",
    "\n",
    "images.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b32ac34",
   "metadata": {},
   "source": [
    "<u>Je ne conserve que le **path** de l'image et j'ajoute une colonne contenant les **labels** de chaque image</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a52ab808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n",
      "None\n",
      "+---------------------------------------------------+----------+\n",
      "|path                                               |label     |\n",
      "+---------------------------------------------------+----------+\n",
      "|s3://projet9-oba-data/Test/Watermelon/r_106_100.jpg|Watermelon|\n",
      "|s3://projet9-oba-data/Test/Watermelon/r_109_100.jpg|Watermelon|\n",
      "|s3://projet9-oba-data/Test/Watermelon/r_108_100.jpg|Watermelon|\n",
      "|s3://projet9-oba-data/Test/Watermelon/r_107_100.jpg|Watermelon|\n",
      "|s3://projet9-oba-data/Test/Watermelon/r_95_100.jpg |Watermelon|\n",
      "+---------------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None"
     ]
    }
   ],
   "source": [
    "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n",
    "print(images.printSchema())\n",
    "print(images.select('path','label').show(5,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15b199",
   "metadata": {},
   "source": [
    "### b) Préparation du modèle\n",
    "\n",
    "Je vais utiliser la technique du **transfert learning** pour extraire les features des images. J'ai choisi d'utiliser le modèle **MobileNetV2** pour sa rapidité d'exécution comparée à d'autres modèles comme *VGG16* par exemple.\n",
    "\n",
    "Il existe une dernière couche qui sert à classer les images selon 1000 catégories que nous ne voulons pas utiliser. L'idée dans ce projet est de récupérer le **vecteur de caractéristiques de dimensions (1,1,1280)** qui servira, plus tard, au travers d'un moteur de classification à reconnaitre les différents fruits du jeu de données.\n",
    "Comme d'autres modèles similaires, **MobileNetV2**, lorsqu'on l'utilise en incluant toutes ses couches, attend obligatoirement des images de dimension (224,224,3). Nos images étant toutes de dimension (100,100,3), nous devrons simplement les **redimensionner** avant de les confier au modèle.\n",
    "\n",
    "<u>Dans l'odre</u> :\n",
    " 1. Nous chargeons le modèle **MobileNetV2** avec les poids **précalculés** issus d'**imagenet** et en spécifiant le format de nos images en entrée\n",
    " 2. Nous créons un nouveau modèle avec:\n",
    "  - <u>en entrée</u> : l'entrée du modèle MobileNetV2\n",
    "  - <u>en sortie</u> : l'avant dernière couche du modèle MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec7c7165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
      "\r",
      "\u001b[1m       0/14536120\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0s/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m   49152/14536120\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 2us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m   81920/14536120\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 3us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m  147456/14536120\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 2us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m  212992/14536120\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 2us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m  278528/14536120\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 1us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m  393216/14536120\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 1us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m  589824/14536120\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 1us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m  811008/14536120\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 1us/step \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m 1163264/14536120\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m 1687552/14536120\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m 2400256/14536120\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m 3497984/14536120\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m 5013504/14536120\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m 7315456/14536120\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m 8478720/14536120\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m11067392/14536120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m12500992/14536120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 0us/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "\u001b[1m14536120/14536120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step"
     ]
    }
   ],
   "source": [
    "# Création du modèle MobileNetV2 avec l'ensemble des couches :\n",
    "model = MobileNetV2(weights='imagenet', include_top=True, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b8405-201d-4c48-8291-656a7d9cd7aa",
   "metadata": {},
   "source": [
    "Affichage du résumé de notre nouveau modèle où nous constatons que <u>nous récupérons bien en sortie un vecteur de dimension (1, 1, 1280)</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b9bc650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Création du modèle spécifique (retrait de la dernière couche): \n",
    "new_model = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "\n",
    "# Diffusion des poids du modèle :\n",
    "brodcast_weights = sc.broadcast(new_model.get_weights())\n",
    "\n",
    "# Résumé du modèle\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47264b0-719a-481e-b2ed-cf0a82f6ac1a",
   "metadata": {},
   "source": [
    "Tous les workeurs doivent pouvoir accéder au modèle ainsi qu'à ses poids. Une bonne pratique consiste à charger le modèle sur le driver puis à diffuser ensuite les poids aux différents workeurs.\n",
    "\n",
    "<u>Mettons cela sous forme de fonction</u>.\n",
    "\n",
    "### c) Fonctions de chargement & de traitement des images & creation des features\n",
    "\n",
    "Ce notebook définit la logique par étapes, jusqu'à Pandas UDF.\n",
    "L'empilement des appels est la suivante :\n",
    "- Pandas UDF\n",
    "- featuriser une série d'images pd.Series\n",
    "- prétraiter une image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be8fe2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns a MobileNetV2 model with top layer removed and broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    new_model = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "    new_model.set_weights(brodcast_weights.value)\n",
    "    return new_model\n",
    "\n",
    "def preprocess(content):\n",
    "    \"\"\"\n",
    "    Preprocesses raw image bytes for prediction.\n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)\n",
    "\n",
    "def featurize_series(model, content_series):\n",
    "    \"\"\"\n",
    "    Featurize a pd.Series of raw images using the input model.\n",
    "    :return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    input = np.stack(content_series.map(preprocess))\n",
    "    preds = model.predict(input)\n",
    "    # For some layers, output features will be multi-dimensional tensors.\n",
    "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)\n",
    "\n",
    "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
    "def featurize_udf(content_series_iter):\n",
    "    '''\n",
    "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
    "\n",
    "    :param content_series_iter: This argument is an iterator over batches of data, where each batch is a pandas Series of image data.\n",
    "    '''\n",
    "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
    "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
    "    model = model_fn()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_series(model, content_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005eb00f",
   "metadata": {},
   "source": [
    "### d) Exécution des actions d'extraction de features\n",
    "\n",
    "Les Pandas UDF, sur de grands enregistrements (par exemple, de très grandes images), peuvent rencontrer des erreurs de type Out Of Memory (OOM).\n",
    "Si vous rencontrez de telles erreurs dans la cellule ci-dessous, essayez de réduire la taille du lot Arrow via 'maxRecordsPerBatch'\n",
    "Je n'utiliserai pas cette commande dans ce projet et je laisse donc la commande en commentaire.\n",
    "\n",
    "Nous pouvons maintenant exécuter la featurisation sur l'ensemble de notre DataFrame Spark.\n",
    "<u>REMARQUE</u> : Cela peut prendre beaucoup de temps, tout dépend du volume de données à traiter.\n",
    "Notre jeu de données de **Test** contient **22819 images**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22d760c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")\n",
    "\n",
    "# Extraction des features en utilisant 21 partitions : \n",
    "features_df = images.repartition(21).select(col(\"path\"), col(\"label\"), featurize_udf(\"content\").alias(\"features\"))\n",
    "\n",
    "features_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb051c07",
   "metadata": {},
   "source": [
    "### e) ACP\n",
    "\n",
    "Cette ACP est réalisée dans Spark et non pas dans scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f9ffc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance expliqu?e par chaque composante principale :\n",
      "[0.1014099130425472,0.08005981651535385,0.06350302718082,0.05014785531069757,0.035354277761087655,0.0291599319836993,0.027732146814681394,0.02284889389541205,0.01985943570194587,0.0190915273951655,0.016537073756515547,0.014662889455521197,0.013981834223290643,0.01368578231395087,0.013347894522772534,0.012500332847094574,0.011550825659275506,0.010749219889392,0.009800369937620823,0.009710070622970876,0.009158305487468892,0.008282988110141443,0.007887717765771638,0.007507839166401488,0.007148164607314943,0.0070723543600667215,0.00683641148804439,0.006218355823197223,0.006122050457134876,0.005890478930769407,0.0057031458892763546,0.005575825947177239,0.005273852071953272,0.005050017949146899,0.004785237405823075,0.0046883810733760085,0.004595275012393054,0.004346392145729127,0.004235182372862692,0.004092068423945076,0.003902364777139975,0.0038892783689277316,0.003844463960579333,0.003723693952167754,0.0036299162765013842,0.0034221999334444002,0.0033970266793011306,0.003330737284489191,0.003290558599125634,0.0032370504328045205,0.0031993554615418313,0.0030567530187354196,0.0029699726025311755,0.002883061981959456,0.002830049486321639,0.0027926953498828254,0.002753771115001577,0.0026880785076336838,0.0025981133193415168,0.00252495437528963,0.0024820407892627563,0.0024517243678668205,0.002351546695425339,0.0023183334869610614,0.0022919207212763588,0.00224517767218765,0.0021947078148253914,0.002168694842697834,0.0021262312815577334,0.002112490406737278,0.002062515991657454,0.001992723674319893,0.0019316371771546837,0.00190709471413682,0.001871012496699437,0.001845218171065436,0.0018031356703428027,0.0017512841475580815,0.0017465195273436596,0.0017303082370868598,0.0017059629202714889,0.0016903004383373936,0.0016460949993881446,0.0016258452282084926,0.0016200518302124582,0.001579606184897878,0.0015586461438648245,0.0015151284729943636,0.001508241486845472,0.0014780041185224152,0.0014463369070257992,0.0014223587971819683,0.001411923300000306,0.0014050993808801006,0.001392696668296611,0.0013634586580962124,0.001358205041060715,0.0013065263608338636,0.001288227201489911,0.0012770443983494638,0.0012582931060456186,0.0012449152900855173,0.0012375049015952333,0.0012148054748630393,0.001201930059878543,0.001187414521611131,0.0011620386636330584,0.0011529519806411095,0.0011267512490086167,0.0011197947672039288,0.0011154069087578706,0.0010837848332256106,0.001075603044489239,0.0010720137950763573,0.00105258732491816,0.0010453498739850624,0.0010332725729008112,0.001028339201957613,0.0009961534777189285,0.0009916797775771443,0.0009802950469803933,0.0009578925687286554,0.0009473273856072761,0.0009455434568020728,0.0009328946402733294,0.0009272326576821006,0.000921711173163812,0.0009084492061545247,0.0008958548232002876,0.0008891581718823043,0.0008760769914798587,0.0008650729957998297,0.0008559442865714945,0.0008435354980564651,0.0008370782159763088,0.0008231386280110809,0.0008157522798688764,0.0008128311464869782,0.0008023820148363046,0.0007912276195808929,0.000783955272387301,0.0007742265148646472,0.0007641702504998978,0.0007593591039610484,0.0007552932718724543,0.0007497246763883085,0.0007369396683188328,0.0007296880440813054,0.0007227722224206662,0.0007213130460368671,0.0007135526881294061,0.0006985800139029649,0.0006969176572021519,0.0006924929259201756,0.0006813785731967701,0.0006781424573106204,0.000672137933516996,0.0006679961118595677,0.000658767606364989,0.0006585604175573382,0.0006467200446625959,0.0006414375930377424,0.0006384575635188198,0.00062829874672504,0.0006210901915413356,0.0006191886926996543,0.0006182958044237594,0.0006066754763070892,0.0006011416025434163,0.0005978132387649973,0.0005919699903339862,0.000587936735972727,0.0005784778696324854,0.0005723320105480352,0.0005701206623316124,0.0005663032753895885,0.0005595662110495368,0.0005571633420682649,0.0005511228845046284,0.0005423316928775792,0.0005411904900537888,0.0005387547147039781,0.000533244699262576,0.0005294418758279576,0.0005246924084373705,0.0005170545308098572,0.0005158089005480657,0.0005126082494557525,0.0005081146626228318,0.0005045031563652271,0.0004968197364992271,0.0004912621757881438,0.0004864968517271648,0.00048307278205973227,0.0004769020162400956,0.0004735285391258093,0.00047239942156518025,0.00046924563587508015,0.00046727235015540713,0.0004613036330536956]\n",
      "Somme de la variance expliqu?e par les k composantes principales : 0.9073574537706676"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "# Définir une UDF pour convertir un array de floats en un vecteur\n",
    "array_to_vector = udf(lambda x: Vectors.dense(x), VectorUDT())\n",
    "\n",
    "# Appliquer l'UDF à la colonne `features`\n",
    "features_df = features_df.withColumn(\"features_vector\", array_to_vector(features_df[\"features\"]))\n",
    "\n",
    "# Utiliser cette nouvelle colonne avec PCA\n",
    "pca = PCA(k=200, inputCol=\"features_vector\", outputCol=\"reduced_features\")\n",
    "pca_model = pca.fit(features_df)\n",
    "\n",
    "# Examiner la variance expliquée pour ajuster 'k'\n",
    "print(\"Variance expliquée par chaque composante principale :\")\n",
    "print(pca_model.explainedVariance)\n",
    "\n",
    "# Somme de la variance expliquée par les k composantes principales\n",
    "total_variance_explained = pca_model.explainedVariance.sum()\n",
    "print(\"Somme de la variance expliquée par les k composantes principales :\", total_variance_explained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86b22840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+\n",
      "|                path|         label|    reduced_features|\n",
      "+--------------------+--------------+--------------------+\n",
      "|s3://projet9-oba-...|    Watermelon|[-3.1191640377446...|\n",
      "|s3://projet9-oba-...|    Watermelon|[1.10923363586790...|\n",
      "|s3://projet9-oba-...|    Watermelon|[-1.9238940051017...|\n",
      "|s3://projet9-oba-...|    Watermelon|[-3.0128143651585...|\n",
      "|s3://projet9-oba-...|Pineapple Mini|[-6.4304468478088...|\n",
      "+--------------------+--------------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Transformer le DataFrame pour obtenir les caractéristiques réduites\n",
    "features_reduced_df = pca_model.transform(features_df)\n",
    "\n",
    "# Sélectionner les colonnes d'intérêt et afficher le résultat\n",
    "final_df = features_reduced_df.select(\"path\", \"label\", \"reduced_features\")\n",
    "final_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dce70737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- reduced_features: vector (nullable = true)"
     ]
    }
   ],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "852b31d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "\n",
    "# Définir une UDF pour convertir un vecteur en array de floats\n",
    "vector_to_array = udf(lambda v: v.toArray().tolist(), ArrayType(FloatType()))\n",
    "\n",
    "# Appliquer l'UDF à la colonne `reduced_features` pour créer une nouvelle colonne `features`\n",
    "final_df = final_df.withColumn(\"features\", vector_to_array(final_df[\"reduced_features\"]))\n",
    "\n",
    "# Supprimer la colonne `reduced_features` si elle n'est plus nécessaire\n",
    "final_df = final_df.drop(\"reduced_features\")\n",
    "\n",
    "# Vérifier le schéma du DataFrame modifié\n",
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab46d857",
   "metadata": {},
   "source": [
    "# 4. Enregistrement du résultat\n",
    "\n",
    "<u>Rappel du PATH où seront inscrits les fichiers au format \"**parquet**\" contenant nos résultats, à savoir, un DataFrame contenant 3 colonnes</u> :\n",
    " 1. Path des images\n",
    " 2. Label de l'image\n",
    " 3. Vecteur de caractéristiques de l'image\n",
    "\n",
    "<u>Enregistrement des données traitées au format \"**parquet**\"</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06a930b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://projet9-oba-data/Results"
     ]
    }
   ],
   "source": [
    "print(PATH_Result)\n",
    "\n",
    "final_df.write.mode(\"overwrite\").parquet(PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe01b72",
   "metadata": {},
   "source": [
    "# 5. Chargement des données enregistrées et validation du résultat\n",
    "\n",
    "<u>On charge les données fraichement enregistrées dans un **DataFrame Pandas**, puis on affiche les 5 premières lignes du DataFrame</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db18a784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_parquet(PATH_Result, engine='pyarrow')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be65f91-71b5-42dd-a223-fb271684c803",
   "metadata": {},
   "source": [
    "<u>On valide que la dimension du vecteur de caractéristiques des images est bien de dimension 1280</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b29205ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)"
     ]
    }
   ],
   "source": [
    "df.loc[0,'features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fba6455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22688, 3)"
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcf1fa7",
   "metadata": {},
   "source": [
    "<u>On peut également constater la présence des fichiers au format \"**parquet**\" sur le **serveur S3**</u>\n",
    "\n",
    "# 6. Sauvegarde des résultats en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c4ad905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convertir la colonne 'features' contenant des listes en un DataFrame séparé\n",
    "features_df = pd.DataFrame(df['features'].tolist())\n",
    "\n",
    "# Renommer les colonnes du nouveau DataFrame pour refléter qu'elles sont des composantes\n",
    "features_df.columns = [f'feature_{i}' for i in range(features_df.shape[1])]\n",
    "\n",
    "# Concaténer le DataFrame original (sans la colonne 'features') avec le nouveau DataFrame des composantes\n",
    "df_final = pd.concat([df.drop('features', axis=1), features_df], axis=1)\n",
    "\n",
    "# Enregistrement du DataFrame en tant que fichier CSV sur S3\n",
    "df_final.to_csv(PATH_Result + '/df_results_aws_emr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b345c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                path  ... feature_199\n",
      "0  s3://projet9-oba-data/Test/Watermelon/r_78_100...  ...    0.600454\n",
      "1  s3://projet9-oba-data/Test/Watermelon/r_169_10...  ...   -0.278663\n",
      "2  s3://projet9-oba-data/Test/Watermelon/202_100.jpg  ...   -0.325102\n",
      "3   s3://projet9-oba-data/Test/Raspberry/238_100.jpg  ...    0.748535\n",
      "4   s3://projet9-oba-data/Test/Raspberry/235_100.jpg  ...    0.619722\n",
      "\n",
      "[5 rows x 202 columns]"
     ]
    }
   ],
   "source": [
    "# Vérification de l'enregistrement : \n",
    "df_final = pd.read_csv(PATH_Result + '/df_results_aws_emr.csv')\n",
    "\n",
    "# Affichage des 5 premières lignes : \n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfa69e7-f2c1-431d-858b-348cc3742144",
   "metadata": {},
   "source": [
    "# 7. Conclusion\n",
    "\n",
    "Nous avons réalisé ce projet en tenant compte des contraintes qui nous ont été imposées.\n",
    "\n",
    "Nous avons fait le choix de réaliser du **transfert learning** à partir du model **MobileNetV2**. Ce modèle a été retenu pour sa **légèreté** et sa **rapidité d'exécution** ainsi que pour la **faible dimension de son vecteur en sortie**.\n",
    "Les résultats ont été enregistrés sur disque en plusieurs partitions au format \"**parquet**\".\n",
    "\n",
    "Dans ce notebook, nous créée un **réel cluster de calculs**. L'objectif était de pouvoir **anticiper une future augmentation de la charge de travail**.\n",
    "Le meilleur choix retenu a été l'utilisation du prestataire de services **Amazon Web Services** qui nous permet de **louer à la demande de la puissance de calculs**, pour un **coût tout à fait acceptable**. Ce service se nomme **EC2** et se classe parmi les offres **Infrastructure As A Service** (IAAS).\n",
    "\n",
    "Nous sommes allés plus loin en utilisant un service de plus haut niveau (**Plateforme As A Service** PAAS) en utilisant le service **EMR** qui nous permet d'un seul coup d'**instancier plusieurs serveur (un cluster)** sur lesquels nous avons pu demander l'installation et la configuration de plusieurs programmes et librairies nécessaires à notre projet comme **Spark**, **Hadoop**, **JupyterHub** ainsi que la librairie **TensorFlow**.\n",
    "En plus d'être plus **rapide et efficace à mettre en place**, nous avons la **certitude du bon fonctionnement de la solution**, celle-ci ayant été préalablement validé par les ingénieurs d'Amazon.\n",
    "Nous avons également pu installer, sans difficulté, **les packages nécessaires sur l'ensembles des machines du cluster**.\n",
    "Enfin, avec très peu de modification, et plus simplement encore, nous avons pu **exécuter notre notebook comme nous l'avions fait localement**. Nous avons cette fois-ci exécuté le traitement sur **l'ensemble des images de notre dossier \"Test\"**.\n",
    "\n",
    "Nous avons opté pour le service **Amazon S3** pour **stocker les données de notre projet**. S3 offre, pour un faible coût, toutes les conditions dont nous avons besoin pour stocker et exploiter de manière efficace nos données. L'espace alloué est potentiellement **illimité**, mais les coûts seront fonction de l'espace utilisé.\n",
    "\n",
    "Il nous sera **facile de faire face à une montée de la charge de travail** en **redimensionnant** simplement notre cluster de machines (horizontalement et/ou verticalement au besoin), les coûts augmenteront en conséquence mais resteront nettement inférieurs aux coûts engendrés par l'achat de matériels ou par la location de serveurs dédiés."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "432.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
